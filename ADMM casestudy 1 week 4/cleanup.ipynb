{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dimension tables...\n",
      "Loading fact tables...\n",
      "Removed 'CarrierTrackingNumber' column from FactInternetSales.\n",
      "\n",
      "-- Checking PK uniqueness in dimension tables --\n",
      "All rows in DimCustomer have a unique 'CustomerKey'.\n",
      "All rows in DimEmployee have a unique 'EmployeeKey'.\n",
      "All rows in DimGeography have a unique 'GeographyKey'.\n",
      "All rows in DimProduct have a unique 'ProductKey'.\n",
      "All rows in DimReseller have a unique 'ResellerKey'.\n",
      "All rows in DimSalesTerritory have a unique 'SalesTerritoryKey'.\n",
      "Filling 56 missing 'Color' cells in DimProduct with 'NA'.\n",
      "Dropped 1 row(s) from DimSalesTerritory due to missing data.\n",
      "Dropped 44 row(s) from FactResellerSales due to missing data.\n",
      "\n",
      "-- Validating foreign keys in FactInternetSales --\n",
      "All rows in FactInternetSales have a valid foreign key 'CustomerKey'.\n",
      "All rows in FactInternetSales have a valid foreign key 'ProductKey'.\n",
      "All rows in FactInternetSales have a valid foreign key 'SalesTerritoryKey'.\n",
      "\n",
      "-- Validating foreign keys in FactResellerSales --\n",
      "All rows in FactResellerSales have a valid foreign key 'ResellerKey'.\n",
      "All rows in FactResellerSales have a valid foreign key 'EmployeeKey'.\n",
      "All rows in FactResellerSales have a valid foreign key 'ProductKey'.\n",
      "All rows in FactResellerSales have a valid foreign key 'SalesTerritoryKey'.\n",
      "\n",
      "-- Loading data into MySQL --\n",
      "\n",
      "ETL process completed successfully!\n",
      "Your star schema now has 6 dimension tables and 2 fact tables.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Adventure Works ETL\n",
    "#\n",
    "# **Key Requirements**:\n",
    "# 1. DimProduct: fill missing \"Color\" with \"NA\".\n",
    "# 2. DimSalesTerritory: drop entire row if any column is missing.\n",
    "# 3. FactInternetSales & FactResellerSales: drop entire row if any column is missing.\n",
    "# 4. Remove \"CarrierTrackingNumber\" from FactInternetSales.\n",
    "# 5. Preserve data types by specifying dtype when reading Excel, parse date columns in fact tables.\n",
    "# 6. Validate foreign keys in fact tables, drop only invalid references.\n",
    "# 7. Load final tables into MySQL.\n",
    "\n",
    "# %% [code]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# -------------------------------\n",
    "# 1. MySQL connection parameters\n",
    "# -------------------------------\n",
    "username = 'root'\n",
    "password = '12345'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database = 'case7'\n",
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Helper functions\n",
    "# -------------------------------\n",
    "def check_uniqueness(df, key_column, table_name):\n",
    "    \"\"\"\n",
    "    Ensures the primary key column is unique.\n",
    "    Drops duplicates based on the PK and prints how many were dropped.\n",
    "    \"\"\"\n",
    "    before = df.shape[0]\n",
    "    df_clean = df.drop_duplicates(subset=[key_column])\n",
    "    after = df_clean.shape[0]\n",
    "    dropped = before - after\n",
    "    if dropped > 0:\n",
    "        print(f\"{dropped} duplicate row(s) dropped from {table_name} based on primary key '{key_column}'.\")\n",
    "    else:\n",
    "        print(f\"All rows in {table_name} have a unique '{key_column}'.\")\n",
    "    return df_clean\n",
    "\n",
    "def validate_fk(fact_df, dim_df, fact_fk, dim_pk, fact_table_name, dim_table_name):\n",
    "    \"\"\"\n",
    "    Drops rows in the fact table where the FK is not in the dimension's PK set.\n",
    "    Prints the number of rows dropped.\n",
    "    \"\"\"\n",
    "    valid_ids = set(dim_df[dim_pk].unique())\n",
    "    before = fact_df.shape[0]\n",
    "    fact_df_clean = fact_df[fact_df[fact_fk].isin(valid_ids)]\n",
    "    after = fact_df_clean.shape[0]\n",
    "    dropped = before - after\n",
    "    if dropped > 0:\n",
    "        print(f\"{dropped} row(s) dropped from {fact_table_name} due to invalid '{fact_fk}' not found in {dim_table_name}.\")\n",
    "    else:\n",
    "        print(f\"All rows in {fact_table_name} have a valid foreign key '{fact_fk}'.\")\n",
    "    return fact_df_clean\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Read Dimension Tables\n",
    "# -------------------------------\n",
    "print(\"Loading dimension tables...\")\n",
    "\n",
    "dim_customer_df = pd.read_excel(\n",
    "    'DimTables.xlsx',\n",
    "    sheet_name='DimCustomer',\n",
    "    dtype={\n",
    "        'CustomerKey': 'Int64',\n",
    "        'GeographyKey': 'Int64',\n",
    "        'CustomerName': 'string',\n",
    "        'BirthDate': 'string',\n",
    "        'MaritalStatus': 'string',\n",
    "        'Gender': 'string',\n",
    "        'EmailAddress': 'string',\n",
    "        'YearlyIncome': 'float',\n",
    "        'Education': 'string',\n",
    "        'Occupation': 'string',\n",
    "        'HouseOwnerFlag': 'string',\n",
    "        'Address': 'string',\n",
    "        'FirstPurchaseDate': 'string'\n",
    "    }\n",
    ")\n",
    "\n",
    "dim_employee_df = pd.read_excel(\n",
    "    'DimTables.xlsx',\n",
    "    sheet_name='DimEmployee',\n",
    "    dtype={\n",
    "        'EmployeeKey': 'Int64',\n",
    "        'ParentEmployeeKey': 'Int64',\n",
    "        'SalesTerritoryKey': 'Int64',\n",
    "        'EmployeeName': 'string',\n",
    "        'Title': 'string',\n",
    "        'EmailAddress': 'string',\n",
    "        'DepartmentName': 'string',\n",
    "        'HireDate': 'string',\n",
    "        'BirthDate': 'string'\n",
    "    }\n",
    ")\n",
    "\n",
    "dim_geography_df = pd.read_excel(\n",
    "    'DimTables.xlsx',\n",
    "    sheet_name='DimGeography',\n",
    "    dtype={\n",
    "        'GeographyKey': 'Int64',\n",
    "        'City': 'string',\n",
    "        'State': 'string',\n",
    "        'Country': 'string',\n",
    "        'PostalCode': 'string',\n",
    "        'SalesTerritoryKey': 'Int64'\n",
    "    }\n",
    ")\n",
    "\n",
    "dim_product_df = pd.read_excel(\n",
    "    'DimTables.xlsx',\n",
    "    sheet_name='DimProduct',\n",
    "    dtype={\n",
    "        'ProductKey': 'Int64',\n",
    "        'ProductSubcategoryKey': 'Int64',\n",
    "        'Product': 'string',\n",
    "        'Color': 'string',\n",
    "        'Model': 'string',\n",
    "        'Subcategory': 'string',\n",
    "        'Category': 'string'\n",
    "    }\n",
    ")\n",
    "\n",
    "dim_reseller_df = pd.read_excel(\n",
    "    'DimTables.xlsx',\n",
    "    sheet_name='DimReseller',\n",
    "    dtype={\n",
    "        'ResellerKey': 'Int64',\n",
    "        'GeographyKey': 'Int64',\n",
    "        'BusinessType': 'string',\n",
    "        'ResellerName': 'string'\n",
    "    }\n",
    ")\n",
    "\n",
    "dim_salesterritory_df = pd.read_excel(\n",
    "    'DimTables.xlsx',\n",
    "    sheet_name='DimSalesTerritory',\n",
    "    dtype={\n",
    "        'SalesTerritoryKey': 'Int64',\n",
    "        'SalesTerritoryRegion': 'string',\n",
    "        'SalesTerritoryCountry': 'string',\n",
    "        'SalesTerritoryGroup': 'string'\n",
    "    }\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Read Fact Tables\n",
    "# -------------------------------\n",
    "print(\"Loading fact tables...\")\n",
    "\n",
    "fact_internet_sales_df = pd.read_excel(\n",
    "    'FactInternetSales.xlsx',\n",
    "    dtype={\n",
    "        'ProductKey': 'Int64',\n",
    "        'CustomerKey': 'Int64',\n",
    "        'SalesTerritoryKey': 'Int64',\n",
    "        'SalesOrderNumber': 'string',\n",
    "        'SalesOrderLineNumber': 'Int64',\n",
    "        'DiscountAmount': 'float',\n",
    "        'TotalProductCost': 'float',\n",
    "        'SalesAmount': 'float',\n",
    "        'Freight': 'float',\n",
    "        'CarrierTrackingNumber': 'string',  # Will remove\n",
    "    },\n",
    "    parse_dates=['OrderDate', 'DueDate', 'ShipDate']\n",
    ")\n",
    "\n",
    "fact_reseller_sales_df = pd.read_excel(\n",
    "    'FactResellerSales.xlsx',\n",
    "    dtype={\n",
    "        'ProductKey': 'Int64',\n",
    "        'ResellerKey': 'Int64',\n",
    "        'EmployeeKey': 'Int64',\n",
    "        'SalesTerritoryKey': 'Int64',\n",
    "        'SalesOrderNumber': 'string',\n",
    "        'SalesOrderLineNumber': 'Int64',\n",
    "        'DiscountAmount': 'float',\n",
    "        'TotalProductCost': 'float',\n",
    "        'SalesAmount': 'float',\n",
    "        'Freight': 'float',\n",
    "        'CarrierTrackingNumber': 'string',\n",
    "    },\n",
    "    parse_dates=['OrderDate', 'DueDate', 'ShipDate']\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Remove 'CarrierTrackingNumber' from FactInternetSales\n",
    "# -------------------------------\n",
    "if 'CarrierTrackingNumber' in fact_internet_sales_df.columns:\n",
    "    fact_internet_sales_df.drop(columns=['CarrierTrackingNumber'], inplace=True)\n",
    "    print(\"Removed 'CarrierTrackingNumber' column from FactInternetSales.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Check Primary Key Uniqueness\n",
    "# -------------------------------\n",
    "print(\"\\n-- Checking PK uniqueness in dimension tables --\")\n",
    "dim_customer_df = check_uniqueness(dim_customer_df, 'CustomerKey', 'DimCustomer')\n",
    "dim_employee_df = check_uniqueness(dim_employee_df, 'EmployeeKey', 'DimEmployee')\n",
    "dim_geography_df = check_uniqueness(dim_geography_df, 'GeographyKey', 'DimGeography')\n",
    "dim_product_df = check_uniqueness(dim_product_df, 'ProductKey', 'DimProduct')\n",
    "dim_reseller_df = check_uniqueness(dim_reseller_df, 'ResellerKey', 'DimReseller')\n",
    "dim_salesterritory_df = check_uniqueness(dim_salesterritory_df, 'SalesTerritoryKey', 'DimSalesTerritory')\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Handle Missing Data\n",
    "# -------------------------------\n",
    "#\n",
    "# Per your requirement:\n",
    "# - DimProduct: fill missing \"Color\" with \"NA\"\n",
    "# - DimSalesTerritory: drop entire row if there's any missing data\n",
    "# - FactInternetSales & FactResellerSales: drop entire row if there's any missing data\n",
    "\n",
    "# 7a. DimProduct -> fill missing color with \"NA\"\n",
    "if 'Color' in dim_product_df.columns:\n",
    "    missing_color = dim_product_df['Color'].isnull().sum()\n",
    "    if missing_color > 0:\n",
    "        print(f\"Filling {missing_color} missing 'Color' cells in DimProduct with 'NA'.\")\n",
    "        dim_product_df['Color'] = dim_product_df['Color'].fillna('NA')\n",
    "\n",
    "# 7b. DimSalesTerritory -> drop entire row if there's missing data\n",
    "before_dst = dim_salesterritory_df.shape[0]\n",
    "dim_salesterritory_df.dropna(inplace=True)\n",
    "after_dst = dim_salesterritory_df.shape[0]\n",
    "dropped_dst = before_dst - after_dst\n",
    "if dropped_dst > 0:\n",
    "    print(f\"Dropped {dropped_dst} row(s) from DimSalesTerritory due to missing data.\")\n",
    "\n",
    "# 7c. FactInternetSales -> drop entire row if there's missing data\n",
    "before_fis = fact_internet_sales_df.shape[0]\n",
    "fact_internet_sales_df.dropna(inplace=True)\n",
    "after_fis = fact_internet_sales_df.shape[0]\n",
    "dropped_fis = before_fis - after_fis\n",
    "if dropped_fis > 0:\n",
    "    print(f\"Dropped {dropped_fis} row(s) from FactInternetSales due to missing data.\")\n",
    "\n",
    "# 7d. FactResellerSales -> drop entire row if there's missing data\n",
    "before_frs = fact_reseller_sales_df.shape[0]\n",
    "fact_reseller_sales_df.dropna(inplace=True)\n",
    "after_frs = fact_reseller_sales_df.shape[0]\n",
    "dropped_frs = before_frs - after_frs\n",
    "if dropped_frs > 0:\n",
    "    print(f\"Dropped {dropped_frs} row(s) from FactResellerSales due to missing data.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Validate Foreign Keys\n",
    "# -------------------------------\n",
    "print(\"\\n-- Validating foreign keys in FactInternetSales --\")\n",
    "fact_internet_sales_df = validate_fk(\n",
    "    fact_internet_sales_df,\n",
    "    dim_customer_df,\n",
    "    'CustomerKey',\n",
    "    'CustomerKey',\n",
    "    'FactInternetSales',\n",
    "    'DimCustomer'\n",
    ")\n",
    "fact_internet_sales_df = validate_fk(\n",
    "    fact_internet_sales_df,\n",
    "    dim_product_df,\n",
    "    'ProductKey',\n",
    "    'ProductKey',\n",
    "    'FactInternetSales',\n",
    "    'DimProduct'\n",
    ")\n",
    "fact_internet_sales_df = validate_fk(\n",
    "    fact_internet_sales_df,\n",
    "    dim_salesterritory_df,\n",
    "    'SalesTerritoryKey',\n",
    "    'SalesTerritoryKey',\n",
    "    'FactInternetSales',\n",
    "    'DimSalesTerritory'\n",
    ")\n",
    "\n",
    "print(\"\\n-- Validating foreign keys in FactResellerSales --\")\n",
    "fact_reseller_sales_df = validate_fk(\n",
    "    fact_reseller_sales_df,\n",
    "    dim_reseller_df,\n",
    "    'ResellerKey',\n",
    "    'ResellerKey',\n",
    "    'FactResellerSales',\n",
    "    'DimReseller'\n",
    ")\n",
    "fact_reseller_sales_df = validate_fk(\n",
    "    fact_reseller_sales_df,\n",
    "    dim_employee_df,\n",
    "    'EmployeeKey',\n",
    "    'EmployeeKey',\n",
    "    'FactResellerSales',\n",
    "    'DimEmployee'\n",
    ")\n",
    "fact_reseller_sales_df = validate_fk(\n",
    "    fact_reseller_sales_df,\n",
    "    dim_product_df,\n",
    "    'ProductKey',\n",
    "    'ProductKey',\n",
    "    'FactResellerSales',\n",
    "    'DimProduct'\n",
    ")\n",
    "fact_reseller_sales_df = validate_fk(\n",
    "    fact_reseller_sales_df,\n",
    "    dim_salesterritory_df,\n",
    "    'SalesTerritoryKey',\n",
    "    'SalesTerritoryKey',\n",
    "    'FactResellerSales',\n",
    "    'DimSalesTerritory'\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Load to MySQL\n",
    "# -------------------------------\n",
    "print(\"\\n-- Loading data into MySQL --\")\n",
    "\n",
    "dim_customer_df.to_sql('dimcustomer', con=engine, if_exists='replace', index=False)\n",
    "dim_employee_df.to_sql('dimemployee', con=engine, if_exists='replace', index=False)\n",
    "dim_geography_df.to_sql('dimgeography', con=engine, if_exists='replace', index=False)\n",
    "dim_product_df.to_sql('dimproduct', con=engine, if_exists='replace', index=False)\n",
    "dim_reseller_df.to_sql('dimreseller', con=engine, if_exists='replace', index=False)\n",
    "dim_salesterritory_df.to_sql('dimsalesterritory', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "fact_internet_sales_df.to_sql('fact_internetsales', con=engine, if_exists='replace', index=False)\n",
    "fact_reseller_sales_df.to_sql('fact_resellersales', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"\\nETL process completed successfully!\")\n",
    "print(\"Your star schema now has 6 dimension tables and 2 fact tables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values remain in DimProduct\n",
      "No missing values remain in DimSalesTerritory\n",
      "No missing values remain in FactResellerSales\n"
     ]
    }
   ],
   "source": [
    "def debug_missing(df, table_name):\n",
    "    # Find columns that still contain missing values\n",
    "    missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "    if len(missing_cols) == 0:\n",
    "        print(f\"No missing values remain in {table_name}\")\n",
    "    else:\n",
    "        print(f\"Columns still missing in {table_name}: {missing_cols}\")\n",
    "        for col in missing_cols:\n",
    "            count = df[col].isnull().sum()\n",
    "            print(f\"  -> {col} has {count} missing values\")\n",
    "\n",
    "# After your fill_missing_dimension() or fill_missing_fact() calls, do:\n",
    "debug_missing(dim_product_df, \"DimProduct\")\n",
    "debug_missing(dim_salesterritory_df, \"DimSalesTerritory\")\n",
    "debug_missing(fact_reseller_sales_df, \"FactResellerSales\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
