{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1c5d27-f95f-4d1e-aefb-fd1ebff8eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 1. Data Extraction\n",
    "excel_file = 'SAP-DataSet.xlsx'\n",
    "\n",
    "# Reading different sheets into DataFrames\n",
    "vbak_df = pd.read_excel(excel_file, sheet_name='VBAK')   # Sales Order Header\n",
    "vbap_df = pd.read_excel(excel_file, sheet_name='VBAP')   # Sales Order Items\n",
    "kna1_df = pd.read_excel(excel_file, sheet_name='KNA1')   # Customer Master\n",
    "likp_df = pd.read_excel(excel_file, sheet_name='LIKP')   # Delivery Header\n",
    "lips_df = pd.read_excel(excel_file, sheet_name='LIPS')   # Delivery Items\n",
    "vttk_df = pd.read_excel(excel_file, sheet_name='VTTK')   # Shipment Header\n",
    "vttp_df = pd.read_excel(excel_file, sheet_name='VTTP')   # Shipment Items\n",
    "lfa1_df = pd.read_excel(excel_file, sheet_name='LFA1')   # Carrier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb444f2-adf5-43c0-9500-32a2f07631fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Validation and Transformation\n",
    "\n",
    "# Rename columns to standardized names\n",
    "kna1_rename = {\n",
    "    'Customer ID': 'customer_id',\n",
    "    'Customer Name': 'customer_name',\n",
    "    'Country': 'country',\n",
    "    'Region': 'region',\n",
    "    'City': 'city',\n",
    "    'Postal Code': 'postal_code',\n",
    "    'Street Address': 'street_address',\n",
    "    'Phone Number': 'phone_number',\n",
    "    'Email Address': 'email_address',\n",
    "    'Language': 'language',\n",
    "    'Tax Number': 'tax_number',\n",
    "    'Customer Group': 'customer_group',\n",
    "    'Sales Organization': 'sales_organization',\n",
    "    'Distribution Channel': 'distribution_channel',\n",
    "    'Division': 'division'\n",
    "}\n",
    "kna1_df.rename(columns=kna1_rename, inplace=True)\n",
    "\n",
    "lfa1_rename = {\n",
    "    'Vendor Number': 'vendor_number',\n",
    "    'Vendor Name': 'vendor_name',\n",
    "    'Country': 'country',\n",
    "    'Region': 'region',\n",
    "    'City': 'city',\n",
    "    'Postal Code': 'postal_code',\n",
    "    'Street Address': 'street_address',\n",
    "    'Phone Number': 'phone_number',\n",
    "    'Email Address': 'email_address',\n",
    "    'Language': 'language',\n",
    "    'Tax Number': 'tax_number',\n",
    "    'Payment Terms': 'payment_terms'\n",
    "}\n",
    "lfa1_df.rename(columns=lfa1_rename, inplace=True)\n",
    "\n",
    "vbak_rename = {\n",
    "    'Sales Document': 'order_id',\n",
    "    'Order Date': 'order_date',\n",
    "    'Customer ID': 'customer_id',\n",
    "    'Order Type': 'order_type',\n",
    "    'Sales Organization': 'sales_organization',\n",
    "    'Distribution Channel': 'distribution_channel',\n",
    "    'Division': 'division',\n",
    "    'Order Status': 'order_status'\n",
    "}\n",
    "vbak_df.rename(columns=vbak_rename, inplace=True)\n",
    "\n",
    "vbap_rename = {\n",
    "    'Sales Document': 'order_id',\n",
    "    'Item Number': 'item_number',\n",
    "    'Material Number': 'material_number',\n",
    "    'Quantity': 'quantity',\n",
    "    'Net Price': 'net_price',\n",
    "    'Item Status': 'item_status',\n",
    "    'Delivery Date': 'delivery_date'\n",
    "}\n",
    "vbap_df.rename(columns=vbap_rename, inplace=True)\n",
    "\n",
    "likp_rename = {\n",
    "    'Delivery Number': 'delivery_number',\n",
    "    'Delivery Date': 'delivery_date',\n",
    "    'Sales Document': 'order_id',\n",
    "    'Shipping Point': 'shipping_point',\n",
    "    'Shipping Type': 'shipping_type',\n",
    "    'Delivery Status': 'delivery_status',\n",
    "    'Shipping Status': 'shipping_status',\n",
    "    'Route': 'route',\n",
    "    'Delivery Priority': 'delivery_priority',\n",
    "    'Customer ID': 'customer_id'\n",
    "}\n",
    "likp_df.rename(columns=likp_rename, inplace=True)\n",
    "\n",
    "lips_rename = {\n",
    "    'Delivery Number': 'delivery_number',\n",
    "    'Item Number': 'item_number',\n",
    "    'Material Number': 'material_number',\n",
    "    'Delivered Quantity': 'delivered_quantity',\n",
    "    'Net Price': 'net_price',\n",
    "    'Delivery Status': 'delivery_status',\n",
    "    'Customer ID': 'customer_id',\n",
    "    'Sales Document': 'order_id',\n",
    "    'Sales Item': 'sales_item',\n",
    "    'Delivery Date': 'delivery_date'\n",
    "}\n",
    "lips_df.rename(columns=lips_rename, inplace=True)\n",
    "\n",
    "vttk_rename = {\n",
    "    'Shipment Number': 'shipment_number',\n",
    "    'Shipment Date': 'shipment_date',\n",
    "    'Sales Document': 'order_id',\n",
    "    'Delivery Number': 'delivery_number',\n",
    "    'Shipping Point': 'shipping_point',\n",
    "    'Carrier': 'carrier',\n",
    "    'Shipment Status': 'shipment_status',\n",
    "    'Route': 'route',\n",
    "    'Shipping Type': 'shipping_type',\n",
    "    'Customer ID': 'customer_id'\n",
    "}\n",
    "vttk_df.rename(columns=vttk_rename, inplace=True)\n",
    "\n",
    "vttp_rename = {\n",
    "    'Shipment Number': 'shipment_number',\n",
    "    'Item Number': 'item_number',\n",
    "    'Material Number': 'material_number',\n",
    "    'Shipped Quantity': 'shipped_quantity',\n",
    "    'Item Status': 'item_status',\n",
    "    'Delivery Number': 'delivery_number',\n",
    "    'Customer ID': 'customer_id',\n",
    "    'Sales Document': 'order_id',\n",
    "    'Sales Item': 'sales_item',\n",
    "    'Shipment Date': 'shipment_date'\n",
    "}\n",
    "vttp_df.rename(columns=vttp_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd80b174-4b1b-4102-af52-9a6ba2ecc296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate missing values in essential fields\n",
    "essential_fields = {\n",
    "    'KNA1': ['customer_id', 'customer_name', 'email_address'],\n",
    "    'LFA1': ['vendor_number', 'vendor_name'],\n",
    "    'VBAK': ['order_id', 'customer_id', 'order_date'],\n",
    "    'VBAP': ['order_id', 'item_number', 'material_number'],\n",
    "    'LIKP': ['delivery_number', 'delivery_date', 'order_id', 'customer_id'],\n",
    "    'LIPS': ['delivery_number', 'item_number', 'material_number'],\n",
    "    'VTTK': ['shipment_number', 'shipment_date', 'order_id', 'carrier'],\n",
    "    'VTTP': ['shipment_number', 'item_number', 'material_number']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2f2bd2-aa95-4e1b-8948-d283808e77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_missing(df, columns, df_name):\n",
    "    missing = df[columns].isnull().sum()\n",
    "    print(f\"Missing values in {df_name}:\")\n",
    "    print(missing)\n",
    "    if missing.sum() > 0:\n",
    "        raise ValueError(f\"{df_name} has missing values in essential fields.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0198e55-fc41-4f40-8495-7e13718d56e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in KNA1:\n",
      "customer_id      0\n",
      "customer_name    0\n",
      "email_address    0\n",
      "dtype: int64\n",
      "Missing values in LFA1:\n",
      "vendor_number    0\n",
      "vendor_name      0\n",
      "dtype: int64\n",
      "Missing values in VBAK:\n",
      "order_id       0\n",
      "customer_id    0\n",
      "order_date     0\n",
      "dtype: int64\n",
      "Missing values in VBAP:\n",
      "order_id           0\n",
      "item_number        0\n",
      "material_number    0\n",
      "dtype: int64\n",
      "Missing values in LIKP:\n",
      "delivery_number    0\n",
      "delivery_date      0\n",
      "order_id           0\n",
      "customer_id        0\n",
      "dtype: int64\n",
      "Missing values in LIPS:\n",
      "delivery_number    0\n",
      "item_number        0\n",
      "material_number    0\n",
      "dtype: int64\n",
      "Missing values in VTTK:\n",
      "shipment_number    0\n",
      "shipment_date      0\n",
      "order_id           0\n",
      "carrier            0\n",
      "dtype: int64\n",
      "Missing values in VTTP:\n",
      "shipment_number    0\n",
      "item_number        0\n",
      "material_number    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "validate_missing(kna1_df, essential_fields['KNA1'], 'KNA1')\n",
    "validate_missing(lfa1_df, essential_fields['LFA1'], 'LFA1')\n",
    "validate_missing(vbak_df, essential_fields['VBAK'], 'VBAK')\n",
    "validate_missing(vbap_df, essential_fields['VBAP'], 'VBAP')\n",
    "validate_missing(likp_df, essential_fields['LIKP'], 'LIKP')\n",
    "validate_missing(lips_df, essential_fields['LIPS'], 'LIPS')\n",
    "validate_missing(vttk_df, essential_fields['VTTK'], 'VTTK')\n",
    "validate_missing(vttp_df, essential_fields['VTTP'], 'VTTP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e213ae23-6977-4fd6-b159-d84239b592d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All orders have valid customers.\n"
     ]
    }
   ],
   "source": [
    "# Referential Integrity: Ensure every order has a valid customer\n",
    "invalid_customers = set(vbak_df['customer_id']) - set(kna1_df['customer_id'])\n",
    "if invalid_customers:\n",
    "    raise ValueError(f\"Invalid customer IDs in orders: {invalid_customers}\")\n",
    "else:\n",
    "    print(\"All orders have valid customers.\")\n",
    "\n",
    "# Convert date columns to datetime\n",
    "def convert_dates(df, date_cols):\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "vbak_df = convert_dates(vbak_df, ['order_date'])\n",
    "likp_df = convert_dates(likp_df, ['delivery_date'])\n",
    "lips_df = convert_dates(lips_df, ['delivery_date'])\n",
    "vttk_df = convert_dates(vttk_df, ['shipment_date'])\n",
    "vttp_df = convert_dates(vttp_df, ['shipment_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8233e3b6-41a0-454c-8f42-04f1dbe6c713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates in VBAK for key order_id.\n",
      "No duplicates in KNA1 for key customer_id.\n",
      "No duplicates in LIKP for key delivery_number.\n",
      "No duplicates in LFA1 for key vendor_number.\n",
      "No duplicates in VTTK for key shipment_number.\n"
     ]
    }
   ],
   "source": [
    "# Strip extra whitespace from string columns\n",
    "def strip_strings(df):\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "    return df\n",
    "\n",
    "for df in [kna1_df, lfa1_df, vbak_df, vbap_df, likp_df, lips_df, vttk_df, vttp_df]:\n",
    "    strip_strings(df)\n",
    "\n",
    "# Check for duplicate records in key columns\n",
    "def check_duplicates(df, key, df_name):\n",
    "    duplicates = df[df.duplicated(subset=[key], keep=False)]\n",
    "    if not duplicates.empty:\n",
    "        raise ValueError(f\"Duplicates found in {df_name} for key {key}.\")\n",
    "    else:\n",
    "        print(f\"No duplicates in {df_name} for key {key}.\")\n",
    "\n",
    "check_duplicates(vbak_df, 'order_id', 'VBAK')\n",
    "check_duplicates(kna1_df, 'customer_id', 'KNA1')\n",
    "check_duplicates(likp_df, 'delivery_number', 'LIKP')\n",
    "check_duplicates(lfa1_df, 'vendor_number', 'LFA1')\n",
    "check_duplicates(vttk_df, 'shipment_number', 'VTTK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb2fb9e-2d0a-44eb-882b-be1552bc1fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Transformation\n",
    "\n",
    "# Build Orders table by merging VBAK and VBAP on order_id\n",
    "orders_df = pd.merge(vbak_df, vbap_df, on='order_id', how='left', suffixes=('_header', '_item'))\n",
    "# Merge LIKP to get delivery_date (used here to compute processing time)\n",
    "orders_df = pd.merge(orders_df, likp_df[['order_id', 'delivery_date']], on='order_id', how='left')\n",
    "# Compute processing time (in days)\n",
    "orders_df['processing_time'] = (orders_df['delivery_date_x'] - orders_df['order_date']).dt.days\n",
    "\n",
    "# Customers table from KNA1 (all columns are kept)\n",
    "customers_df = kna1_df.copy()\n",
    "\n",
    "# Shipments table: Merge LIKP (delivery header) with VTTK (shipment header) using delivery_number.\n",
    "shipments_df = pd.merge(likp_df, vttk_df[['delivery_number', 'shipment_number', 'shipment_date', 'carrier', 'shipment_status']], on='delivery_number', how='left')\n",
    "\n",
    "# Shipment_Items table directly from LIPS\n",
    "shipment_items_df = lips_df.copy()\n",
    "\n",
    "# Carriers table from LFA1 (all columns)\n",
    "carriers_df = lfa1_df.copy()\n",
    "\n",
    "# Delivery_Status table: Merge VTTK (shipment header) with VTTP (shipment items) on shipment_number.\n",
    "delivery_status_df = pd.merge(vttk_df, vttp_df, on='shipment_number', how='left')\n",
    "\n",
    "delivery_status_df = delivery_status_df.drop(columns=[col for col in delivery_status_df.columns if col.endswith('_y')])\n",
    "delivery_status_df = delivery_status_df.rename(columns=lambda col: col.replace('_x', ''))\n",
    "\n",
    "# Optionally, attach shipping status from LIKP if desired\n",
    "if 'shipping_status' in likp_df.columns:\n",
    "    delivery_status_df = pd.merge(delivery_status_df, likp_df[['delivery_number', 'shipping_status']], on='delivery_number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d164c0-a14b-472f-8b82-d84fcad8878b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "200b1c33-5209-4e22-9b45-10b99b17959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the MySQL database!\n",
      "Data loaded to MySQL successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Database connection details\n",
    "DB_USER = \"root\"\n",
    "DB_PASSWORD = \"12345\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"3306\"\n",
    "DB_NAME = \"case11\"\n",
    "\n",
    "# Create the engine using pymysql\n",
    "engine = create_engine(f\"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "print(\"Successfully connected to the MySQL database!\")\n",
    "\n",
    "# Example of pushing data to MySQL\n",
    "tables_to_push = {\n",
    "    \"delivery_status\": delivery_status_df,\n",
    "    \"orders\": orders_df,\n",
    "    \"carriers\": carriers_df,\n",
    "}\n",
    "\n",
    "# Directly replace existing tables\n",
    "for table_name, df in tables_to_push.items():\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data loaded to MySQL successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
