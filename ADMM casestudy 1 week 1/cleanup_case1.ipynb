{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAP ERP Data Integration for Order Fulfillment & Delivery Analytics\n",
    "\n",
    "This notebook demonstrates an end-to-end ETL process:\n",
    "\n",
    "**Data Extraction:**  \n",
    "Extract data from SAP ERP Excel sheets (KNA1, LFA1, VBAK, VBAP, LIKP, LIPS, VTTK, VTTP).\n",
    "\n",
    "**Data Transformation:**  \n",
    "Build a relational data model with these tables:\n",
    "- **customers:** Data from KNA1.\n",
    "- **sap_customers:** Duplicate of customers (optional).\n",
    "- **orders:** Header-level order data from VBAK.\n",
    "- **order_items:** Item-level order details from VBAP.\n",
    "- **shipments:** Delivery header data from LIKP.\n",
    "- **shipment_items:** Delivery item data from LIPS.\n",
    "- **carriers:** Carrier information from LFA1.\n",
    "- **delivery_status:** Merged shipment status info from VTTK and VTTP.\n",
    "- **delivery_analytics:** Aggregated delivery performance metrics.\n",
    "\n",
    "**Data Validation:**  \n",
    "Checks include primary key uniqueness, referential integrity, and format validations.\n",
    "\n",
    "**Data Load:**  \n",
    "Load the data into a MySQL database (table names in lower-case).\n",
    "\n",
    "**Prerequisites:**  \n",
    "Ensure you have installed: `pandas`, `sqlalchemy`, `pymysql`, `openpyxl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheets: ['KNA1', 'LFA1', 'VBAK', 'VBAP', 'LIKP', 'LIPS', 'VTTK', 'VTTP']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "\n",
    "# Define the Excel file path (update the path if needed)\n",
    "excel_file = 'SAP-DataSet.xlsx'\n",
    "\n",
    "# Load the Excel file and list available sheet names\n",
    "xls = pd.ExcelFile(excel_file)\n",
    "print(\"Available sheets:\", xls.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "Load each relevant sheet into a DataFrame. The sheets and key columns are:\n",
    "- **KNA1:** Customer master data\n",
    "- **LFA1:** Vendor data (used here as Carriers)\n",
    "- **VBAK:** Sales Order Header\n",
    "- **VBAP:** Sales Order Items\n",
    "- **LIKP:** Delivery Header\n",
    "- **LIPS:** Delivery Items\n",
    "- **VTTK:** Shipment Header\n",
    "- **VTTP:** Shipment Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kna1 = pd.read_excel(excel_file, sheet_name='KNA1')\n",
    "df_lfa1 = pd.read_excel(excel_file, sheet_name='LFA1')\n",
    "df_vbak = pd.read_excel(excel_file, sheet_name='VBAK')\n",
    "df_vbap = pd.read_excel(excel_file, sheet_name='VBAP')\n",
    "df_likp = pd.read_excel(excel_file, sheet_name='LIKP')\n",
    "df_lips = pd.read_excel(excel_file, sheet_name='LIPS')\n",
    "df_vttk = pd.read_excel(excel_file, sheet_name='VTTK')\n",
    "df_vttp = pd.read_excel(excel_file, sheet_name='VTTP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Customers and SAP_Customers Tables\n",
    "Use the KNA1 sheet to build the customers table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = df_kna1.copy()\n",
    "customers_df.rename(columns={\n",
    "    'Customer ID': 'customer_id',\n",
    "    'Customer Name': 'customer_name',\n",
    "    'Country': 'country',\n",
    "    'Region': 'region',\n",
    "    'City': 'city',\n",
    "    'Postal Code': 'postal_code',\n",
    "    'Street Address': 'street_address',\n",
    "    'Phone Number': 'phone_number',\n",
    "    'Email Address': 'email_address',\n",
    "    'Language': 'language',\n",
    "    'Tax Number': 'tax_number',\n",
    "    'Customer Group': 'customer_group',\n",
    "    'Sales Organization': 'sales_organization',\n",
    "    'Distribution Channel': 'distribution_channel',\n",
    "    'Division': 'division'\n",
    "}, inplace=True)\n",
    "sap_customers_df = customers_df.copy()  # Optional duplicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Orders and Order_Items Tables\n",
    "**Orders:** Derived from VBAK (order header).  \n",
    "**Order_Items:** Derived from VBAP (order item details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = df_vbak.copy()\n",
    "orders_df.rename(columns={\n",
    "    'Sales Document': 'order_id',\n",
    "    'Order Date': 'order_date',\n",
    "    'Customer ID': 'customer_id',\n",
    "    'Order Type': 'order_type',\n",
    "    'Sales Organization': 'sales_organization',\n",
    "    'Distribution Channel': 'distribution_channel',\n",
    "    'Division': 'division',\n",
    "    'Order Status': 'order_status'\n",
    "}, inplace=True)\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'], errors='coerce')\n",
    "\n",
    "order_items_df = df_vbap.copy()\n",
    "order_items_df.rename(columns={\n",
    "    'Sales Document': 'order_id',\n",
    "    'Item Number': 'item_number',\n",
    "    'Material Number': 'product_id',\n",
    "    'Quantity': 'order_quantity',\n",
    "    'Net Price': 'unit_price',\n",
    "    'Item Status': 'item_status',\n",
    "    'Delivery Date': 'delivery_date'\n",
    "}, inplace=True)\n",
    "order_items_df['delivery_date'] = pd.to_datetime(order_items_df['delivery_date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shipments and Shipment_Items Tables\n",
    "**Shipments:** Based on LIKP (delivery header).  \n",
    "**Shipment_Items:** Based on LIPS (delivery items)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipments_df = df_likp.copy()\n",
    "shipments_df.rename(columns={\n",
    "    'Delivery Number': 'shipment_id',\n",
    "    'Delivery Date': 'shipment_date',\n",
    "    'Sales Document': 'order_id',\n",
    "    'Shipping Point': 'shipping_point',\n",
    "    'Shipping Type': 'shipping_type',\n",
    "    'Delivery Status': 'delivery_status',\n",
    "    'Shipping Status': 'shipping_status',\n",
    "    'Route': 'route',\n",
    "    'Delivery Priority': 'delivery_priority',\n",
    "    'Customer ID': 'customer_id'\n",
    "}, inplace=True)\n",
    "shipments_df['shipment_date'] = pd.to_datetime(shipments_df['shipment_date'], errors='coerce')\n",
    "\n",
    "# %%\n",
    "shipment_items_df = df_lips.copy()\n",
    "shipment_items_df.rename(columns={\n",
    "    'Delivery Number': 'shipment_id',\n",
    "    'Item Number': 'item_number',\n",
    "    'Material Number': 'product_id',\n",
    "    'Delivered Quantity': 'shipped_quantity',\n",
    "    'Net Price': 'unit_price',\n",
    "    'Delivery Status': 'delivery_status',\n",
    "    'Customer ID': 'customer_id',\n",
    "    'Sales Document': 'order_id',\n",
    "    'Sales Item': 'sales_item',\n",
    "    'Delivery Date': 'delivery_date'\n",
    "}, inplace=True)\n",
    "shipment_items_df['delivery_date'] = pd.to_datetime(shipment_items_df['delivery_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Carriers Table\n",
    "Use the LFA1 sheet as carriers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "carriers_df = df_lfa1.copy()\n",
    "carriers_df.rename(columns={\n",
    "    'Vendor Number': 'carrier_id',\n",
    "    'Vendor Name': 'carrier_name',\n",
    "    'Country': 'country',\n",
    "    'Region': 'region',\n",
    "    'City': 'city',\n",
    "    'Postal Code': 'postal_code',\n",
    "    'Street Address': 'street_address',\n",
    "    'Phone Number': 'phone_number',\n",
    "    'Email Address': 'email_address',\n",
    "    'Language': 'language',\n",
    "    'Tax Number': 'tax_number',\n",
    "    'Payment Terms': 'payment_terms'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Delivery_Status Table\n",
    "Merge VTTK (shipment header) and VTTP (shipment items) to build the delivery_status table.\n",
    "Because both sheets have common columns (e.g. \"Shipment Date\"), suffixes are applied.\n",
    "We use the header values for key fields by renaming:\n",
    "  - \"Shipment Date_header\" → \"shipment_date\"\n",
    "  - \"Sales Document_header\" → \"order_id\"\n",
    "  - \"Delivery Number_header\" → \"shipment_id\"\n",
    "  - \"Customer ID_header\" → \"customer_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_status_df = pd.merge(df_vttk, df_vttp, on='Shipment Number', how='inner', \n",
    "                              suffixes=('_header', '_item'))\n",
    "# Rename columns using header values\n",
    "delivery_status_df.rename(columns={\n",
    "    'Shipment Number': 'shipment_number',\n",
    "    'Shipment Date_header': 'shipment_date',\n",
    "    'Shipment Status': 'shipment_status',\n",
    "    'Carrier': 'carrier',\n",
    "    'Sales Document_header': 'order_id',\n",
    "    'Delivery Number_header': 'shipment_id',\n",
    "    'Customer ID_header': 'customer_id'\n",
    "}, inplace=True)\n",
    "delivery_status_df['shipment_date'] = pd.to_datetime(delivery_status_df['shipment_date'], errors='coerce')\n",
    "delivery_status_df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Delivery_Analytics Table\n",
    "Compute performance metrics by joining orders and shipments.\n",
    "For each order, calculate:\n",
    "  - **delivery_time:** Difference in days between order_date and earliest shipment_date.\n",
    "  - **on_time:** Flag if delivery_time is within a threshold (e.g. ≤ 3 days).\n",
    "  - **delay_reason:** 'Delayed' if not on time, otherwise blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_shipments = pd.merge(orders_df[['order_id','order_date','customer_id']], \n",
    "                            shipments_df[['shipment_id','order_id','shipment_date']], \n",
    "                            on='order_id', how='left')\n",
    "agg_shipments = orders_shipments.groupby('order_id').agg({'shipment_date': 'min'}).reset_index()\n",
    "delivery_analytics_df = pd.merge(orders_df[['order_id','order_date','customer_id']], \n",
    "                                 agg_shipments, on='order_id', how='left')\n",
    "delivery_analytics_df['delivery_time'] = (delivery_analytics_df['shipment_date'] - delivery_analytics_df['order_date']).dt.days\n",
    "threshold = 3\n",
    "delivery_analytics_df['on_time'] = np.where(delivery_analytics_df['delivery_time'] <= threshold, True, False)\n",
    "delivery_analytics_df['delay_reason'] = np.where(delivery_analytics_df['on_time'], '', 'Delayed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation Checks\n",
    "Validate primary key uniqueness and foreign key consistency using helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary key check passed for customers.\n",
      "Primary key check passed for orders.\n",
      "Primary key check passed for order_items.\n",
      "Primary key check passed for shipments.\n",
      "Primary key check passed for shipment_items.\n",
      "Primary key check passed for carriers.\n",
      "WARNING: Duplicates in delivery_status for key columns ['shipment_number']:\n",
      "   shipment_number\n",
      "1          2001001\n",
      "Primary key check passed for delivery_analytics.\n",
      "Foreign key check passed for orders (customer_id).\n",
      "Foreign key check passed for order_items (order_id).\n",
      "Foreign key check passed for shipments (order_id).\n",
      "Foreign key check passed for shipment_items (order_id).\n",
      "Foreign key check passed for delivery_status (order_id).\n",
      "Foreign key check passed for delivery_analytics (customer_id).\n"
     ]
    }
   ],
   "source": [
    "def check_primary_key_uniqueness(df, key_columns, table_name):\n",
    "    duplicates = df.duplicated(subset=key_columns)\n",
    "    if duplicates.any():\n",
    "        print(f\"WARNING: Duplicates in {table_name} for key columns {key_columns}:\")\n",
    "        print(df[duplicates][key_columns])\n",
    "    else:\n",
    "        print(f\"Primary key check passed for {table_name}.\")\n",
    "\n",
    "def check_foreign_key(child_df, child_key, parent_df, parent_key, table_name):\n",
    "    missing = set(child_df[child_key].dropna()) - set(parent_df[parent_key].dropna())\n",
    "    if missing:\n",
    "        print(f\"WARNING: In {table_name}, the following {child_key} values are missing in parent table: {missing}\")\n",
    "    else:\n",
    "        print(f\"Foreign key check passed for {table_name} ({child_key}).\")\n",
    "        \n",
    "# delivery_status_df.drop_duplicates(subset=['shipment_number'], inplace=True)\n",
    "\n",
    "# Primary key validations\n",
    "check_primary_key_uniqueness(customers_df, ['customer_id'], 'customers')\n",
    "check_primary_key_uniqueness(orders_df, ['order_id'], 'orders')\n",
    "check_primary_key_uniqueness(order_items_df, ['order_id', 'item_number'], 'order_items')\n",
    "check_primary_key_uniqueness(shipments_df, ['shipment_id'], 'shipments')\n",
    "check_primary_key_uniqueness(shipment_items_df, ['shipment_id', 'item_number'], 'shipment_items')\n",
    "check_primary_key_uniqueness(carriers_df, ['carrier_id'], 'carriers')\n",
    "check_primary_key_uniqueness(delivery_status_df, ['shipment_number'], 'delivery_status')\n",
    "check_primary_key_uniqueness(delivery_analytics_df, ['order_id'], 'delivery_analytics')\n",
    "\n",
    "# Foreign key validations\n",
    "check_foreign_key(orders_df, 'customer_id', customers_df, 'customer_id', 'orders')\n",
    "check_foreign_key(order_items_df, 'order_id', orders_df, 'order_id', 'order_items')\n",
    "check_foreign_key(shipments_df, 'order_id', orders_df, 'order_id', 'shipments')\n",
    "check_foreign_key(shipment_items_df, 'order_id', orders_df, 'order_id', 'shipment_items')\n",
    "check_foreign_key(delivery_status_df, 'order_id', orders_df, 'order_id', 'delivery_status')\n",
    "check_foreign_key(delivery_analytics_df, 'customer_id', customers_df, 'customer_id', 'delivery_analytics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data into MySQL\n",
    "Create a MySQL engine and load each DataFrame into corresponding tables.\n",
    "Table names are set to lower-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded to MySQL database successfully.\n"
     ]
    }
   ],
   "source": [
    "username = 'root'\n",
    "password = '12345'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database = 'case1'\n",
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# Load tables to MySQL (table names in lower-case)\n",
    "customers_df.to_sql('customers', con=engine, if_exists='replace', index=False)\n",
    "sap_customers_df.to_sql('sap_customers', con=engine, if_exists='replace', index=False)\n",
    "orders_df.to_sql('orders', con=engine, if_exists='replace', index=False)\n",
    "order_items_df.to_sql('order_items', con=engine, if_exists='replace', index=False)\n",
    "shipments_df.to_sql('shipments', con=engine, if_exists='replace', index=False)\n",
    "shipment_items_df.to_sql('shipment_items', con=engine, if_exists='replace', index=False)\n",
    "carriers_df.to_sql('carriers', con=engine, if_exists='replace', index=False)\n",
    "delivery_status_df.to_sql('delivery_status', con=engine, if_exists='replace', index=False)\n",
    "delivery_analytics_df.to_sql('delivery_analytics', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data loaded to MySQL database successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook has:\n",
    "- Extracted SAP ERP data from an Excel file.\n",
    "- Transformed the data into a SQL data model for order fulfillment and delivery analytics.\n",
    "- Validated data for completeness, uniqueness, and referential integrity.\n",
    "- Loaded the data into a MySQL database with lower-case table names.\n",
    "The resulting data warehouse is now ready for further reporting and analytics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
