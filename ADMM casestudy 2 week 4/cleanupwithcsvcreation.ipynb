{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting names\n",
      "  Downloading names-0.3.0.tar.gz (789 kB)\n",
      "     ---------------------------------------- 0.0/789.1 kB ? eta -:--:--\n",
      "     -------------------------------------- 789.1/789.1 kB 8.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: names\n",
      "  Building wheel for names (setup.py): started\n",
      "  Building wheel for names (setup.py): finished with status 'done'\n",
      "  Created wheel for names: filename=names-0.3.0-py3-none-any.whl size=803711 sha256=54629312f92593308caa31a74770c8af954b4ebcfc885eae6fc30c095f1a8f2b\n",
      "  Stored in directory: C:\\Users\\sayan\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-dlbl5iwp\\wheels\\c7\\f0\\8f\\de9f15941cd988c39b82703fa04cb2d550ba5867f13c6da052\n",
      "Successfully built names\n",
      "Installing collected packages: names\n",
      "Successfully installed names-0.3.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\sayan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\entfa-1.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample CSV files created with >= 10 rows each.\n",
      "CSV files loaded into DataFrames.\n",
      "Data cleaning & validation complete.\n",
      "Star schema created with surrogate keys in dimension tables.\n",
      "Data successfully loaded to MySQL with improved star schema.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Healthcare Patient Analytics ETL & Star Schema (Improved)\n",
    "#\n",
    "# This notebook demonstrates:\n",
    "# 1. Generating >=10 rows per table (Patients, Doctors, Admissions, Vitals, Treatments, Readmission_Risk).\n",
    "# 2. Data cleaning & validation (primary key uniqueness, not-null checks, foreign key checks).\n",
    "# 3. Star Schema with surrogate keys in dimension tables (DimPatients, DimDoctors) and three fact tables:\n",
    "#    - FactAdmissions (merged with readmission risk),\n",
    "#    - FactVitals,\n",
    "#    - FactTreatments.\n",
    "# 4. Loading the final tables into MySQL.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import names\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# For demonstration only; supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Generate Sample Data (>= 10 Rows per Table)\n",
    "\n",
    "def random_date(start_year=2020, end_year=2025):\n",
    "    \"\"\"Generate a random date between start_year and end_year.\"\"\"\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year, 12, 31)\n",
    "    delta = end_date - start_date\n",
    "    random_days = random.randrange(delta.days)\n",
    "    return start_date + timedelta(days=random_days)\n",
    "\n",
    "def random_phone():\n",
    "    \"\"\"Generate a random 10-digit phone number as a string.\"\"\"\n",
    "    return str(random.randint(10**9, 10**10 - 1))\n",
    "\n",
    "def random_diagnosis():\n",
    "    return random.choice([\"Pneumonia\", \"Hypertension\", \"Asthma Attack\", \"Diabetes Complications\", \n",
    "                          \"Heart Failure\", \"Sepsis\", \"Kidney Stones\", \"Migraine\", \"COVID-19\", \"Fracture\"])\n",
    "\n",
    "def random_specialization():\n",
    "    return random.choice([\"Cardiologist\", \"Pulmonologist\", \"General Physician\", \"Neurologist\",\n",
    "                          \"Orthopedic\", \"Endocrinologist\", \"Gastroenterologist\"])\n",
    "\n",
    "def random_chronic_condition():\n",
    "    return random.choice([\"None\", \"Hypertension\", \"Asthma\", \"Diabetes\", \"Heart Disease\", \"None\", \"None\"])\n",
    "\n",
    "# 1.1 Patients (>= 10 rows)\n",
    "num_patients = 10\n",
    "patient_ids = list(range(101, 101 + num_patients))\n",
    "patients_data = []\n",
    "for pid in patient_ids:\n",
    "    patients_data.append([\n",
    "        pid,\n",
    "        names.get_first_name(),\n",
    "        names.get_last_name(),\n",
    "        random_date(1950, 2000).date(),  # dob\n",
    "        random.choice([\"Male\", \"Female\"]),\n",
    "        random_phone(),\n",
    "        f\"{random.randint(100,999)} Main St\",\n",
    "        random_chronic_condition()\n",
    "    ])\n",
    "\n",
    "patients_df = pd.DataFrame(patients_data, columns=[\n",
    "    \"patient_id\", \"first_name\", \"last_name\", \"dob\", \"gender\", \"contact_no\", \"address\", \"chronic_conditions\"\n",
    "])\n",
    "\n",
    "# 1.2 Doctors (>= 10 rows)\n",
    "num_doctors = 10\n",
    "doctor_ids = list(range(301, 301 + num_doctors))\n",
    "doctors_data = []\n",
    "for did in doctor_ids:\n",
    "    doctors_data.append([\n",
    "        did,\n",
    "        names.get_first_name(),\n",
    "        names.get_last_name(),\n",
    "        random_specialization(),\n",
    "        random_phone()\n",
    "    ])\n",
    "\n",
    "doctors_df = pd.DataFrame(doctors_data, columns=[\n",
    "    \"doctor_id\", \"first_name\", \"last_name\", \"specialization\", \"contact_no\"\n",
    "])\n",
    "\n",
    "# 1.3 Admissions (>= 10 rows)\n",
    "# We will ensure each admission references an existing patient & doctor\n",
    "num_admissions = 10\n",
    "admission_ids = list(range(2001, 2001 + num_admissions))\n",
    "admissions_data = []\n",
    "for aid in admission_ids:\n",
    "    patient_id = random.choice(patient_ids)\n",
    "    doctor_id = random.choice(doctor_ids)\n",
    "    admission_date = random_date(2024, 2025)\n",
    "    # Some admissions have not been discharged yet\n",
    "    discharge_date = admission_date + timedelta(days=random.randint(1, 10)) if random.random() > 0.3 else None\n",
    "    diagnosis = random_diagnosis()\n",
    "    room_no = random.choice([\"A101\",\"A102\",\"B210\",\"C305\",\"B405\",\"ICU1\",\"ICU2\",\"D110\",\"D120\",\"E201\"])\n",
    "    admissions_data.append([\n",
    "        aid, patient_id, admission_date.date(),\n",
    "        discharge_date.date() if discharge_date else None,\n",
    "        diagnosis, doctor_id, room_no\n",
    "    ])\n",
    "\n",
    "admissions_df = pd.DataFrame(admissions_data, columns=[\n",
    "    \"admission_id\", \"patient_id\", \"admission_date\", \"discharge_date\",\n",
    "    \"diagnosis\", \"doctor_id\", \"room_no\"\n",
    "])\n",
    "\n",
    "# 1.4 Vitals (>= 10 rows)\n",
    "# Each vitals row references an existing admission\n",
    "num_vitals = 10\n",
    "vital_ids = list(range(5001, 5001 + num_vitals))\n",
    "vitals_data = []\n",
    "for vid in vital_ids:\n",
    "    admission_id = random.choice(admission_ids)\n",
    "    # Just pick a random time near the admission_date\n",
    "    base_date = admissions_df.loc[admissions_df['admission_id'] == admission_id, 'admission_date'].values[0]\n",
    "    # Convert base_date to datetime\n",
    "    base_datetime = pd.to_datetime(base_date)\n",
    "    recorded_time = base_datetime + timedelta(hours=random.randint(0, 100))\n",
    "    heart_rate = random.randint(60, 120)\n",
    "    bp_systolic = random.randint(100, 160)\n",
    "    bp_diastolic = random.randint(70, 100)\n",
    "    blood_pressure = f\"{bp_systolic}/{bp_diastolic}\"\n",
    "    oxygen_level = random.randint(88, 100)\n",
    "    temperature = round(random.uniform(97.0, 103.0), 1)\n",
    "    vitals_data.append([\n",
    "        vid, admission_id, recorded_time, heart_rate, blood_pressure, oxygen_level, temperature\n",
    "    ])\n",
    "\n",
    "vitals_df = pd.DataFrame(vitals_data, columns=[\n",
    "    \"vital_id\", \"admission_id\", \"recorded_time\", \"heart_rate\",\n",
    "    \"blood_pressure\", \"oxygen_level\", \"temperature\"\n",
    "])\n",
    "\n",
    "# 1.5 Treatments (>= 10 rows)\n",
    "num_treatments = 10\n",
    "treatment_ids = list(range(7001, 7001 + num_treatments))\n",
    "treatments_data = []\n",
    "possible_procedures = [\"Nebulization\", \"Blood Pressure Monitoring\", \"ECG\", \"X-Ray\", \n",
    "                       \"MRI Scan\", \"IV Fluid Therapy\", \"Physical Therapy\", \"Vaccination\"]\n",
    "possible_meds = [\"Amoxicillin 500mg\", \"Prednisone 10mg\", \"Metoprolol 50mg\", \"Ibuprofen 400mg\",\n",
    "                 \"Acetaminophen 500mg\", \"Atorvastatin 20mg\", \"Insulin 10units\"]\n",
    "for tid in treatment_ids:\n",
    "    admission_id = random.choice(admission_ids)\n",
    "    # approximate date of treatment around admission_date\n",
    "    base_date = admissions_df.loc[admissions_df['admission_id'] == admission_id, 'admission_date'].values[0]\n",
    "    base_datetime = pd.to_datetime(base_date)\n",
    "    treat_date = base_datetime + timedelta(days=random.randint(0, 5))\n",
    "    procedure = random.choice(possible_procedures)\n",
    "    medication = random.choice(possible_meds)\n",
    "    dosage = random.choice([\"1x daily\", \"2x daily\", \"3x daily\", \"As needed\"])\n",
    "    treatments_data.append([\n",
    "        tid, admission_id, treat_date.date(), procedure, medication, dosage\n",
    "    ])\n",
    "\n",
    "treatments_df = pd.DataFrame(treatments_data, columns=[\n",
    "    \"treatment_id\", \"admission_id\", \"treatment_date\", \"procedure\", \"medication\", \"dosage\"\n",
    "])\n",
    "\n",
    "# 1.6 Readmission_Risk (>= 10 rows)\n",
    "# We'll keep a 1-to-1 relationship with admissions for demonstration\n",
    "risk_ids = list(range(9001, 9001 + num_admissions))\n",
    "risk_data = []\n",
    "for i, aid in enumerate(admission_ids):\n",
    "    pred_date = admissions_df.loc[admissions_df['admission_id'] == aid, 'admission_date'].values[0]\n",
    "    pred_date = pd.to_datetime(pred_date) + timedelta(days=random.randint(0,2))\n",
    "    risk_score = round(random.uniform(0.2, 0.9), 2)\n",
    "    if risk_score < 0.4:\n",
    "        risk_level = \"Low\"\n",
    "    elif risk_score < 0.7:\n",
    "        risk_level = \"Medium\"\n",
    "    else:\n",
    "        risk_level = \"High\"\n",
    "    risk_data.append([\n",
    "        risk_ids[i], aid, pred_date.date(), risk_score, risk_level\n",
    "    ])\n",
    "\n",
    "risk_df = pd.DataFrame(risk_data, columns=[\n",
    "    \"risk_id\", \"admission_id\", \"prediction_date\", \"risk_score\", \"risk_level\"\n",
    "])\n",
    "\n",
    "# Write dataframes to CSV (simulate source files)\n",
    "patients_df.to_csv(\"patients.csv\", index=False)\n",
    "doctors_df.to_csv(\"doctors.csv\", index=False)\n",
    "admissions_df.to_csv(\"admissions.csv\", index=False)\n",
    "vitals_df.to_csv(\"vitals.csv\", index=False)\n",
    "treatments_df.to_csv(\"treatments.csv\", index=False)\n",
    "risk_df.to_csv(\"readmission_risk.csv\", index=False)\n",
    "\n",
    "print(\"Sample CSV files created with >= 10 rows each.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Read CSV Files (Extract Phase)\n",
    "\n",
    "patients = pd.read_csv(\"patients.csv\", parse_dates=[\"dob\"])\n",
    "doctors = pd.read_csv(\"doctors.csv\")\n",
    "admissions = pd.read_csv(\"admissions.csv\", parse_dates=[\"admission_date\", \"discharge_date\"])\n",
    "vitals = pd.read_csv(\"vitals.csv\", parse_dates=[\"recorded_time\"])\n",
    "treatments = pd.read_csv(\"treatments.csv\", parse_dates=[\"treatment_date\"])\n",
    "readmission_risk = pd.read_csv(\"readmission_risk.csv\", parse_dates=[\"prediction_date\"])\n",
    "\n",
    "print(\"CSV files loaded into DataFrames.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Data Cleaning & Validation\n",
    "\n",
    "# ### 3.1 Check Primary Key Uniqueness & Drop Duplicates\n",
    "\n",
    "def check_and_drop_duplicates(df, pk_col, table_name):\n",
    "    dup_count = df.duplicated(subset=[pk_col]).sum()\n",
    "    if dup_count > 0:\n",
    "        print(f\"{table_name}: Dropping {dup_count} duplicate rows based on primary key {pk_col}.\")\n",
    "        df = df.drop_duplicates(subset=[pk_col])\n",
    "    return df\n",
    "\n",
    "patients = check_and_drop_duplicates(patients, \"patient_id\", \"Patients\")\n",
    "doctors = check_and_drop_duplicates(doctors, \"doctor_id\", \"Doctors\")\n",
    "admissions = check_and_drop_duplicates(admissions, \"admission_id\", \"Admissions\")\n",
    "vitals = check_and_drop_duplicates(vitals, \"vital_id\", \"Vitals\")\n",
    "treatments = check_and_drop_duplicates(treatments, \"treatment_id\", \"Treatments\")\n",
    "readmission_risk = check_and_drop_duplicates(readmission_risk, \"risk_id\", \"Readmission_Risk\")\n",
    "\n",
    "# ### 3.2 Check Required (NOT NULL) Columns\n",
    "\n",
    "def drop_missing_required(df, required_cols, table_name):\n",
    "    missing_mask = df[required_cols].isnull().any(axis=1)\n",
    "    missing_count = missing_mask.sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"{table_name}: Dropping {missing_count} rows with missing data in required columns {required_cols}.\")\n",
    "        df = df[~missing_mask]\n",
    "    return df\n",
    "\n",
    "patients = drop_missing_required(patients, [\"patient_id\", \"first_name\", \"last_name\", \"dob\", \"gender\", \"contact_no\"], \"Patients\")\n",
    "doctors = drop_missing_required(doctors, [\"doctor_id\", \"first_name\", \"last_name\", \"specialization\", \"contact_no\"], \"Doctors\")\n",
    "admissions = drop_missing_required(admissions, [\"admission_id\", \"patient_id\", \"admission_date\", \"diagnosis\", \"doctor_id\"], \"Admissions\")\n",
    "vitals = drop_missing_required(vitals, [\"vital_id\", \"admission_id\", \"recorded_time\", \"heart_rate\", \"blood_pressure\", \"oxygen_level\", \"temperature\"], \"Vitals\")\n",
    "treatments = drop_missing_required(treatments, [\"treatment_id\", \"admission_id\", \"treatment_date\", \"medication\"], \"Treatments\")\n",
    "readmission_risk = drop_missing_required(readmission_risk, [\"risk_id\", \"admission_id\", \"prediction_date\", \"risk_score\", \"risk_level\"], \"Readmission_Risk\")\n",
    "\n",
    "# ### 3.3 Validate Foreign Keys\n",
    "\n",
    "# Admissions -> Patients\n",
    "invalid_pat_fk = ~admissions['patient_id'].isin(patients['patient_id'])\n",
    "if invalid_pat_fk.sum() > 0:\n",
    "    print(f\"Admissions: Dropping {invalid_pat_fk.sum()} rows with invalid patient_id.\")\n",
    "    admissions = admissions[~invalid_pat_fk]\n",
    "\n",
    "# Admissions -> Doctors\n",
    "invalid_doc_fk = ~admissions['doctor_id'].isin(doctors['doctor_id'])\n",
    "if invalid_doc_fk.sum() > 0:\n",
    "    print(f\"Admissions: Dropping {invalid_doc_fk.sum()} rows with invalid doctor_id.\")\n",
    "    admissions = admissions[~invalid_doc_fk]\n",
    "\n",
    "# Vitals -> Admissions\n",
    "invalid_adm_fk_v = ~vitals['admission_id'].isin(admissions['admission_id'])\n",
    "if invalid_adm_fk_v.sum() > 0:\n",
    "    print(f\"Vitals: Dropping {invalid_adm_fk_v.sum()} rows with invalid admission_id.\")\n",
    "    vitals = vitals[~invalid_adm_fk_v]\n",
    "\n",
    "# Treatments -> Admissions\n",
    "invalid_adm_fk_t = ~treatments['admission_id'].isin(admissions['admission_id'])\n",
    "if invalid_adm_fk_t.sum() > 0:\n",
    "    print(f\"Treatments: Dropping {invalid_adm_fk_t.sum()} rows with invalid admission_id.\")\n",
    "    treatments = treatments[~invalid_adm_fk_t]\n",
    "\n",
    "# Readmission_Risk -> Admissions\n",
    "invalid_adm_fk_r = ~readmission_risk['admission_id'].isin(admissions['admission_id'])\n",
    "if invalid_adm_fk_r.sum() > 0:\n",
    "    print(f\"Readmission_Risk: Dropping {invalid_adm_fk_r.sum()} rows with invalid admission_id.\")\n",
    "    readmission_risk = readmission_risk[~invalid_adm_fk_r]\n",
    "\n",
    "print(\"Data cleaning & validation complete.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Build Star Schema with Surrogate Keys in Dimension Tables\n",
    "#\n",
    "# **Improvements**:\n",
    "# - We introduce `dim_patients` and `dim_doctors` with **surrogate keys** (`patient_key` and `doctor_key`) instead of using `patient_id` and `doctor_id` directly as PK.\n",
    "# - We create `fact_admissions` by merging `admissions` and `readmission_risk`.\n",
    "# - We keep `fact_vitals` and `fact_treatments` referencing `admission_id`.\n",
    "# - You could also replace `admission_id` with a surrogate key in `fact_admissions` and reference that from `fact_vitals`/`fact_treatments`. For simplicity, we’ll keep `admission_id` as the fact PK.\n",
    "\n",
    "# ### 4.1 Create DimPatients with Surrogate Key\n",
    "dim_patients = patients.copy()\n",
    "dim_patients[\"patient_key\"] = range(1, len(dim_patients) + 1)\n",
    "\n",
    "# Reorder columns: put surrogate key first\n",
    "dim_patients = dim_patients[[\n",
    "    \"patient_key\", \"patient_id\", \"first_name\", \"last_name\", \"dob\",\n",
    "    \"gender\", \"contact_no\", \"address\", \"chronic_conditions\"\n",
    "]]\n",
    "\n",
    "# ### 4.2 Create DimDoctors with Surrogate Key\n",
    "dim_doctors = doctors.copy()\n",
    "dim_doctors[\"doctor_key\"] = range(1, len(dim_doctors) + 1)\n",
    "dim_doctors = dim_doctors[[\n",
    "    \"doctor_key\", \"doctor_id\", \"first_name\", \"last_name\", \"specialization\", \"contact_no\"\n",
    "]]\n",
    "\n",
    "# ### 4.3 Create FactAdmissions (merge with readmission_risk)\n",
    "fact_admissions = admissions.merge(readmission_risk, on=\"admission_id\", how=\"left\")\n",
    "\n",
    "# Replace patient_id with patient_key\n",
    "fact_admissions = fact_admissions.merge(\n",
    "    dim_patients[[\"patient_id\", \"patient_key\"]],\n",
    "    on=\"patient_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Replace doctor_id with doctor_key\n",
    "fact_admissions = fact_admissions.merge(\n",
    "    dim_doctors[[\"doctor_id\", \"doctor_key\"]],\n",
    "    on=\"doctor_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# We can drop the original patient_id/doctor_id if we want to rely solely on surrogate keys in the fact table:\n",
    "# (But keep them for reference if you prefer.)\n",
    "fact_admissions.drop([\"patient_id\", \"doctor_id\"], axis=1, inplace=True)\n",
    "\n",
    "# ### 4.4 FactVitals & FactTreatments remain referencing admission_id\n",
    "fact_vitals = vitals.copy()\n",
    "fact_treatments = treatments.copy()\n",
    "\n",
    "print(\"Star schema created with surrogate keys in dimension tables.\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Load to MySQL\n",
    "\n",
    "username = 'root'\n",
    "password = '12345'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database = 'case8'\n",
    "engine = create_engine(f\"mysql+pymysql://{username}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "# For demonstration: write dimension/fact tables\n",
    "dim_patients.to_sql('dim_patients', engine, if_exists='replace', index=False)\n",
    "dim_doctors.to_sql('dim_doctors', engine, if_exists='replace', index=False)\n",
    "fact_admissions.to_sql('fact_admissions', engine, if_exists='replace', index=False)\n",
    "fact_vitals.to_sql('fact_vitals', engine, if_exists='replace', index=False)\n",
    "fact_treatments.to_sql('fact_treatments', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"Data successfully loaded to MySQL with improved star schema.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
