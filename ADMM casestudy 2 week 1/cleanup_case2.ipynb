{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning: 10000\n",
      "Rows after cleaning: 9397\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the sales data from the CSV file\n",
    "sales_df = pd.read_csv('sales 1.csv')\n",
    "\n",
    "# Display the number of rows before cleaning\n",
    "initial_count = sales_df.shape[0]\n",
    "print(\"Rows before cleaning:\", initial_count)\n",
    "\n",
    "# Drop rows where either 'SalesAmount' or 'Quantity' is missing\n",
    "sales_df.dropna(subset=['SalesAmount', 'Quantity'], inplace=True)\n",
    "\n",
    "# Display the number of rows after cleaning\n",
    "final_count = sales_df.shape[0]\n",
    "print(\"Rows after cleaning:\", final_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 duplicate CustomerID(s).\n",
      "Rows with duplicate CustomerIDs:\n",
      "     CustomerID    FirstName   LastName  Gender       Region          SSN\n",
      "22        C0023        Grant   Bartlett    male         Ohio  914-9819-50\n",
      "25        C0026        Jesse  Wilkerson    male           NY  929/20/0753\n",
      "46        C0047         Seth       Hess    Male        Texas    075643618\n",
      "47        C0048        Frank       Ross       M         Ohho  466.83.1539\n",
      "49        C0050     Kimberly     Wright  female      Nw York  556/57/7221\n",
      "...         ...          ...        ...     ...          ...          ...\n",
      "1095      C0939       Sandra       None  female  Californiya  879.28.3301\n",
      "1096      C0965        Scott       None       M         Ohho    226607396\n",
      "1097      C0966  Christopher    Meadows       M         Ohio  249/65/1683\n",
      "1098      C0971         Jeff     Nelson    male           NY    202775865\n",
      "1099      C0989        Lucas     Conley       M           NY  657/00/1176\n",
      "\n",
      "[200 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the customer data\n",
    "customers_df = pd.read_json('customers.json')\n",
    "\n",
    "# Check for duplicate CustomerID values\n",
    "duplicate_count = customers_df.duplicated(subset=['CustomerID']).sum()\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Found {duplicate_count} duplicate CustomerID(s).\")\n",
    "    # Optionally display the rows with duplicate CustomerIDs\n",
    "    duplicates = customers_df[customers_df.duplicated(subset=['CustomerID'], keep=False)]\n",
    "    print(\"Rows with duplicate CustomerIDs:\")\n",
    "    print(duplicates)\n",
    "else:\n",
    "    print(\"No duplicates found. All CustomerID values are unique.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales rows before filtering invalid IDs: 9397\n",
      "Number of customers before cleaning: 1100\n",
      "Number of customers after cleaning: 1000\n",
      "\n",
      "Cleaned Customers Data:\n",
      "  CustomerID FirstName LastName Gender      Region             Name\n",
      "0      C0001   Gregory   Miller   Male        Ohio   Gregory Miller\n",
      "1      C0002    Marvin            Male  California           Marvin\n",
      "2      C0003   Gregory    Smith   Male    New York    Gregory Smith\n",
      "3      C0004    Edward    Davis   Male        Ohio     Edward Davis\n",
      "4      C0005  Reginald   Dawson   Male       Texas  Reginald Dawson\n"
     ]
    }
   ],
   "source": [
    "# Load the customers and products data\n",
    "customers_df = pd.read_json('customers.json')\n",
    "products_df = pd.read_csv('products.csv')\n",
    "print(\"Sales rows before filtering invalid IDs:\", sales_df.shape[0])\n",
    "# Filter sales data: keep rows where CustomerID exists in customers_df and ProductID exists in products_df\n",
    "sales_df = sales_df[\n",
    "    (sales_df['CustomerID'].isin(customers_df['CustomerID'])) &\n",
    "    (sales_df['ProductID'].isin(products_df['ProductID']))\n",
    "]\n",
    "\n",
    "# Number of customers before removing duplicates\n",
    "initial_count = len(customers_df)\n",
    "print(\"Number of customers before cleaning:\", initial_count)\n",
    "\n",
    "# --- Clean Gender ---\n",
    "customers_df['Gender'] = customers_df['Gender'].replace({\n",
    "    'M': 'Male', \n",
    "    'male': 'Male', \n",
    "    'F': 'Female', \n",
    "    'female': 'Female'\n",
    "})\n",
    "\n",
    "# --- Clean Region ---\n",
    "customers_df['Region'] = customers_df['Region'].replace({\n",
    "    'Texaz': 'Texas',\n",
    "    'Ohho': 'Ohio',\n",
    "    'New Yorkk': 'New York',\n",
    "    'NY': 'New York',\n",
    "    'Nw York': 'New York',\n",
    "    'california': 'California',\n",
    "    'Californiya': 'California'\n",
    "})\n",
    "# Replace nulls in Region with \"Unknown\"\n",
    "customers_df['Region'] = customers_df['Region'].fillna(\"Unknown\")\n",
    "\n",
    "# --- Clean LastName ---\n",
    "# Replace nulls in LastName with \"Unknown\", then replace \"Unknown\" with an empty string\n",
    "customers_df['LastName'] = customers_df['LastName'].fillna(\"Unknown\")\n",
    "customers_df['LastName'] = customers_df['LastName'].replace(\"Unknown\", \"\")\n",
    "\n",
    "# --- Remove Duplicates ---\n",
    "# Remove duplicate CustomerIDs, keeping only the first occurrence\n",
    "customers_df = customers_df.drop_duplicates(subset=['CustomerID'], keep='first')\n",
    "\n",
    "# --- Remove Unnecessary Columns ---\n",
    "# Drop the SSN column if it exists\n",
    "if 'SSN' in customers_df.columns:\n",
    "    customers_df = customers_df.drop(columns=['SSN'])\n",
    "\n",
    "# --- Merge Name Columns ---\n",
    "# Combine FirstName and LastName into a new column \"Name\"\n",
    "customers_df['Name'] = (customers_df['FirstName'].astype(str) + \" \" + customers_df['LastName'].astype(str)).str.strip()\n",
    "\n",
    "# ------------------------------\n",
    "# Final Output\n",
    "# ------------------------------\n",
    "final_count = len(customers_df)\n",
    "print(\"Number of customers after cleaning:\", final_count)\n",
    "print(\"\\nCleaned Customers Data:\")\n",
    "print(customers_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with invalid Timestamp format: 0\n",
      "Number of duplicate SaleID entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert the Timestamp column to datetime. Invalid formats will become NaT.\n",
    "sales_df['Timestamp'] = pd.to_datetime(sales_df['Timestamp'], errors='coerce')\n",
    "\n",
    "# Count how many rows have an invalid (NaT) Timestamp\n",
    "invalid_timestamp_count = sales_df['Timestamp'].isna().sum()\n",
    "print(\"Number of rows with invalid Timestamp format:\", invalid_timestamp_count)\n",
    "\n",
    "# Review the rows with invalid timestamps:\n",
    "if invalid_timestamp_count > 0:\n",
    "    print(\"Rows with invalid Timestamp:\")\n",
    "    print(sales_df[sales_df['Timestamp'].isna()])\n",
    "\n",
    "# Check that SaleID is unique\n",
    "duplicate_saleid_count = sales_df['SaleID'].duplicated().sum()\n",
    "print(\"Number of duplicate SaleID entries:\", duplicate_saleid_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed sales data loaded into fact_sales table.\n",
      "Customer data loaded into dim_customers table.\n",
      "Product data loaded into dim_products table.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "username = 'root'\n",
    "password = '12345'\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "database = 'case2'\n",
    "\n",
    "# Create a MySQL engine using PyMySQL driver\n",
    "engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}:{port}/{database}')\n",
    "\n",
    "# 1. Load Transformed Data (Fact Table)\n",
    "sales_df.to_sql('fact_sales', engine, if_exists='replace', index=False)\n",
    "print(\"Transformed sales data loaded into fact_sales table.\")\n",
    "\n",
    "# 2. Load Dimension Tables\n",
    "# Load customers (dimension table for customers)\n",
    "customers_df.to_sql('dim_customers', engine, if_exists='replace', index=False)\n",
    "print(\"Customer data loaded into dim_customers table.\")\n",
    "\n",
    "# Load products (dimension table for products)\n",
    "products_df.to_sql('dim_products', engine, if_exists='replace', index=False)\n",
    "print(\"Product data loaded into dim_products table.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
